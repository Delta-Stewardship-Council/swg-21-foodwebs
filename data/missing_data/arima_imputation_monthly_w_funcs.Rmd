---
title: "ARIMA interpolation for missing data (monthly)"
author: "Denise-Colombano, Sarah Perry"
date: "1/13/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning= FALSE, message=FALSE)
```

# load library
```{r}
library(tidyverse)
library(ggthemes)
library(imputeTS)
library(zoo)
library(forecast)
library(patchwork)
source('functions/missingdat_funcs.R')
```


# TEMPERATURE

# data wrangling
## import data
This is data generated from the "nutrient_data_monthly.Rmd" script written by Sarah Perry (1-13-2022)
```{r}
missingdat_Temperature <- read_csv("data/missing_data/missing_data/missingdat_Temperature.csv") %>% 
  mutate(Date=lubridate::as_date(MonthYear)) %>% 
  select(Date, Analyte:P8) %>%  # rearrange df with date, no time
  arrange(Date)

str(missingdat_Temperature)
head(missingdat_Temperature)
dim(missingdat_Temperature)
View(missingdat_Temperature)
```

## tidy data format
```{r}
# check dataframe:
## check number of rows: 26 years x 12 months = 312 rows
## there are only 310 rows which means there are two missing rows of month x year that need NAs?
## add them back in

Date <- tibble(Date=seq(from=lubridate::as_date("1995-01-01"), to=lubridate::as_date("2020-12-01"), by="1 month")) # 312

# create a new table with all combos = 312
temp_table <- Date %>% 
  left_join(missingdat_Temperature, by="Date")
```



# pilot model
Inspect a single station - see how the original time series is misleading,
needed the full combination of station-month-year with NAs

```{r}
# visualize missing data points
D28A_na <- temp_table %>% 
  select(Date, D28A) %>% # filter out station of interest
  filter(is.na(D28A)) %>% # find NAs
  mutate(D28A=0) # for visualization purposes set to zero

plot_D28A <- ggplot(temp_table, aes(Date, D28A))+
  geom_line()+
  geom_point(data=D28A_na, aes(Date, D28A), pch=4, col="red", size=3)+ # red x = NA
  theme_bw()
plot_D28A
```


Methods: 

Interpolate missing values: ARIMA  
Fit ARIMA models  

ARIMA = complex linear model  
ARIMA(p,d,q) is the series of d-th order difference of ARMA(p, q)   
p = order of the autoregressive (AR) model,   
d = order of non seasonal differences (I integrated part),   
q = order of the movind average (MA) part  

In other words:  
p = dependence on prior values (the number of lag observations in the model; also known as the lag order)  
q = dependence on longer-term values (size of moving average window or order of the moving average)  
d =  degree of differencing of raw observations (number of times the raw data are differenced; allow for the time-series to become stationary by using the differences instead of raw values)  

Other important parameter is the drift = degree of non-stationarity or trends in the data (add a constant corresponding to the mean of the trend yt - yt-1)  
Attention non-stationarity means that the mean will always move by drift and the predicted variance will grow over time. Can be dangerous to forecast into the future!   

Error terms are assumed to be random variables sampled from a normal distribution = random noise  


Special cases  

White noise 	ARIMA(0,0,0)  
Random walk 	ARIMA(0,1,0) with no constant  
Random walk with drift 	ARIMA(0,1,0) with a constant  
Autoregression 	ARIMA(p,0,0)  
Moving average 	ARIMA(0,0,q)   

 
Seasonal ARIMA models  

When data show intra-annual regular and predictable patterns  
These models take into account the seasonality in the data and does the same ARIMA steps but on the seasonal pattern.   
So, if the data has a seasonal pattern every quarter then the SARIMA will get an order for (p,d,q) for all the points and a (P,D,Q) for each quarter  
In this case d is replaced by d + D where D is the order of seasonal differencing and d the order of non-seasonal differencing  

 
The auto.arima function: forecast::auto.arima(y)  

Provide an 'easy' way to estimate all the parameters using a model selection procedure  

The way auto.arima picks the best model is by fitting several models and calculating its AICc score.   
The model with the lowest score is selected as the best model.  
Everything can be automatized and the algorith can skip several steps and approximate the results so that less models are fitted.  
This is very useful for big datasets but can compromise performance so better to check how it works!  

 
A few important parameters  
 
If stationary=TRUE restricts search to stationary models  (default is FALSE)   
If seasonal=FALSE restricts search to non-seasonal models D = 0  (default is TRUE)   
If stepwise=FALSE will search over all models instead of doing a stepwise selection procedure [can be very slow, especially for sesonal models] (default is TRUE)  
If allowdrift = TRUE (default), models with drift terms are considered  
If allowmean = TRUE (default), models with a non-zero mean are considered  
approximation = TRUE  (default)  can be used to avoid excessive computation time by approximating the AICc scores  
lambda: box-cox transformation parameter; if you choose lambda="auto", the parameter will be automatically adjusted. The optimal transformation of the data is used to stabilize the variance of the original time-series (using a power or log transformation). It may produce simpler models and more accurate predictions. You can also choose to transform your values beforehand (e.g., log10)   
Seasonality: auto.arima has the ability to decide whether or not the models needs a seasonal differencing but in noisy data it can be difficult for the algorith to distinguish (especially if using approximations, etc) so it can be useful to specify if you know that your data have a seasonal component. In this case you can specify D = 1 for seasonal model. If missing, will choose a value based on internal ?season.test?  


## fit ARIMA model
```{r}
# time series object using ts - monthly resolution for each year
temp_D28A <- temp_table %>% 
  select(Date, D28A) %>% 
  arrange(Date) # single station still for now
temp_ts <- ts(temp_D28A$D28A, frequency = 12, start = c(1995,1), end=c(2020,12))
temp_ts


# fit arima model
temp_fit <- forecast::auto.arima(temp_ts, seasonal = TRUE, stationary=TRUE, trace = TRUE) #stationary=TRUE for forecasting
# get the same answer with lambda="auto" and unlog data
# if we let stationarity=FALSE, there's a different top model, but it doesn't allow forecasting?
summary(temp_fit)
```
Series: temp_ts 
ARIMA(5,0,0)(1,0,0)[12] with non-zero mean


## predict values using the calibration dataset
```{r}
temp_forecast <- forecast::forecast(temp_ts,model=temp_fit)
```

## compare predicted versus observed values
```{r}
#Plot the observed and predicted temperatures
par(mar=c(2,4,1,1))
plot(temp_D28A$Date,temp_ts,xlab="Date",ylab="Temp (C)",lwd=2,type="l")
lines(temp_D28A$Date,temp_forecast$fitted,col="red")

#Plot predicted versus observed values
plot(temp_ts,temp_forecast$fitted,xlab="Observed",ylab="Predicted",pch=".")
abline(0,1,lty=2)
R2 = round(cor.test(temp_ts,temp_forecast$fitted,na.rm=T)$estimate^2,2)
mtext(side=3,line=-2,adj=0.1,bquote(R^2 == .(R2)))


#Check the residuals
forecast::checkresiduals(temp_fit) 
#give also the results for the Ljung_Box test with H0 = randomly distributed errors (white noise)

#plot residuals versus fitted values (=check for heterosedasticity)
#if problems you might want to try to transform the data first
par(mar=c(4,4,4,4))
plot(temp_forecast$fitted,temp_forecast$residuals,ylab="Residuals",xlab="Fitted values")


#Check several metrics of performance
forecast::accuracy(object = temp_fit) # can also provide a test dataset for cross-validation using x = testUS 
#? ME: Mean Error
#? RMSE: Root Mean Squared Error
#? MAE: Mean Absolute Error
#? MPE: Mean Percentage Error
#? MAPE: Mean Absolute Percentage Error
#? MASE: Mean Absolute Scaled Error
#? ACF1: Autocorrelation of errors at lag 1.


#Missing data imputation
#Interpolate missing values using a Kalman filter (=smoother)
temp_inter <- na_kalman(temp_ts,model=temp_fit$model) #use the fitted model

#Plot the results - Doesn't do a good job with 1980 NAs
par(mar=c(2,4,1,1))
plot(temp_inter,xlab="",ylab="Temperature (C)",col="red",main="Interpolation missing values")
lines(temp_ts,col="black")

#?auto.arima
```

# full model
```{r}
# run model and fit (takes forever)
df_ts <- create_ts_df(temp_table)
model_fits <- eval_fit(temp_table)
```

## diagnostic tests
```{r}
#Plot the observed and predicted temperatures
ggplot(df_ts, aes(Date, Imputed_values, color=Imputed))+
  geom_line(aes(Date, Imputed_values), col="gray60")+  
  geom_point(size=1)+
  facet_wrap(Station~., ncol=3)+
  scale_color_manual(values=c("gray60", "red"))+
  labs(title="Replacing missing values with ARIMA and Kalman filter", subtitle="Temperature (C)")+
  theme_bw()
```

```{r}
# model summary
for (station in names(model_fits)){
  fit <- model_fits[station][[1]]
  # check summary
  print(summary(fit))  

  # check the residuals
  print(forecast::checkresiduals(fit))

  # check several metrics of performance
  print(forecast::accuracy(object = fit))

  # plot residuals versus fitted values (=check for heterosedasticity)
  # if problems you might want to try to transform the data first
  par(mar=c(4,4,4,4))
  plot(fit$fitted, fit$residuals,ylab="Residuals",xlab="Fitted values")
}
```

## export df
```{r}
df_ts %>% write_csv("data/missing_data/imputed_data/temperature_imputed_data.csv")
```

# CHLOROPHYLL

# data wrangling
## import data
This is data generated from the "nutrient_data_monthly.Rmd" script written by Sarah Perry (1-13-2022)
```{r}
missingdat_Chlorophyll <- read_csv("data/missing_data/missing_data/missingdat_Chlorophyll.csv") %>% 
  mutate(Date=lubridate::as_date(MonthYear)) %>% 
  select(Date, Analyte:P8) %>%  # rearrange df with date, no time
  arrange(Date)
str(missingdat_Chlorophyll)
summary(missingdat_Chlorophyll)
dim(missingdat_Chlorophyll)
View(missingdat_Chlorophyll)
```

## tidy data format
```{r}
# check dataframe:
## check number of rows: 26 years x 12 months = 312 rows
## there are only 310 rows which means there are two missing rows of month x year that need NAs?
## add them back in

Date <- tibble(Date=seq(from=lubridate::as_date("1995-01-01"), to=lubridate::as_date("2020-12-01"), by="1 month")) # 312

# create a new table with all combos = 312
chl_table <- Date %>% 
  left_join(missingdat_Chlorophyll, by="Date")
```



# pilot model
Inspect a single station - see how the original time series is misleading,
needed the full combination of station-month-year with NAs

```{r}
# visualize missing data points - 14 missing Chl data points
D28A_na <- chl_table %>% 
  select(Date, D28A) %>% # filter out station of interest
  filter(is.na(D28A)) %>% # find NAs
  mutate(D28A=0) # for visualization purposes set to zero

plot_D28A <- ggplot(chl_table, aes(Date, D28A))+
  geom_line()+
  geom_point(data=D28A_na, aes(Date, D28A), pch=4, col="red", size=3)+ # red x = NA
  theme_bw()
plot_D28A
```


## fit ARIMA model
```{r}
# time series object using ts - monthly resolution for each year
chl_D28A <- chl_table %>% 
  select(Date, D28A) %>% 
  arrange(Date) # single station still for now
chl_ts <- ts(chl_D28A$D28A, frequency = 12, start = c(1995,1), end=c(2020,12))
chl_ts


# fit arima model
chl_fit <- forecast::auto.arima(chl_ts, seasonal=TRUE, trace = TRUE, lambda = "auto", stationary=TRUE) #stationary=TRUE for forecasting
# get the same answer with lambda="auto" and unlog data
# if we let stationarity=FALSE, there's a different top model, but it doesn't allow forecasting?
summary(chl_fit)
```
Series: chl_ts 
ARIMA(2,0,0)(2,0,0)[12] with non-zero mean


## predict values using the calibration dataset
```{r}
chl_forecast <- forecast::forecast(chl_ts,model=chl_fit)
```

## compare predicted versus observed values
```{r}
#Plot the observed and predicted Chlorophyll
par(mar=c(2,4,1,1))
plot(chl_D28A$Date,chl_ts,xlab="Date",ylab="chl (C)",lwd=2,type="l")
lines(chl_D28A$Date,chl_forecast$fitted,col="red")

#Plot predicted versus observed values
plot(chl_ts,chl_forecast$fitted,xlab="Observed",ylab="Predicted",pch=".")
abline(0,1,lty=2)
R2 = round(cor.test(chl_ts,chl_forecast$fitted,na.rm=T)$estimate^2,2)
mtext(side=3,line=-2,adj=0.1,bquote(R^2 == .(R2)))


#Check the residuals
forecast::checkresiduals(chl_fit) 
#give also the results for the Ljung_Box test with H0 = randomly distributed errors (white noise)

#plot residuals versus fitted values (=check for heterosedasticity)
#if problems you might want to try to transform the data first
par(mar=c(4,4,4,4))
plot(chl_forecast$fitted,chl_forecast$residuals,ylab="Residuals",xlab="Fitted values")


#Check several metrics of performance
forecast::accuracy(object = chl_fit) # can also provide a test dataset for cross-validation using x = testUS 
#? ME: Mean Error
#? RMSE: Root Mean Squared Error
#? MAE: Mean Absolute Error
#? MPE: Mean Percentage Error
#? MAPE: Mean Absolute Percentage Error
#? MASE: Mean Absolute Scaled Error
#? ACF1: Autocorrelation of errors at lag 1.


#Missing data imputation
#Interpolate missing values using a Kalman filter (=smoother)
chl_inter <- na_kalman(chl_ts,model=chl_fit$model) #use the fitted model

#Plot the results - Doesn't do a good job with 1980 NAs
par(mar=c(2,4,1,1))
plot(chl_inter,xlab="",ylab="Chlorophyll (C)",col="red",main="Interpolation missing values")
lines(chl_ts,col="black")

#?auto.arima
```

```{r}
# run model and fit (takes forever)
df_ts <- create_ts_df(chl_table)
model_fits <- eval_fit(chl_table)
```

## diagnostic tests
```{r}
# plot the observed and predicted temperatures
ggplot(df_ts, aes(Date, Imputed_values, color=Imputed))+
  geom_line(aes(Date, Imputed_values), col="gray60")+  
  geom_point(size=1)+
  facet_wrap(Station~., ncol=3)+
  scale_color_manual(values=c("gray60", "red"))+
  labs(title="Replacing missing values with ARIMA and Kalman filter", subtitle="Chlorophyll (mg/L)")+
  theme_bw()
```

```{r}
# model summary
for (station in names(model_fits)){
  fit <- model_fits[station][[1]]
  # check summary
  print(summary(fit))  

  # check the residuals
  print(forecast::checkresiduals(fit))

  # check several metrics of performance
  print(forecast::accuracy(object = fit))

  # plot residuals versus fitted values (=check for heterosedasticity)
  # if problems you might want to try to transform the data first
  par(mar=c(4,4,4,4))
  plot(fit$fitted, fit$residuals,ylab="Residuals",xlab="Fitted values")
}
```

## export df
```{r}
df_ts %>% write_csv("data/missing_data/imputed_data/chlorophyll_imputed_data.csv")
```


# DISSOLVED AMMONIA

# data wrangling
## import data
This is data generated from the "nutrient_data_monthly.Rmd" script written by Sarah Perry (1-13-2022)
```{r}
missingdat_Ammonia <- read_csv("data/missing_data/missing_data/missingdat_DissAmmonia.csv") %>%  
  mutate(Date=lubridate::as_date(MonthYear)) %>% 
  select(Date, Analyte:P8) %>%  # rearrange df with date, no time
  arrange(Date)
str(missingdat_Ammonia)
head(missingdat_Ammonia)
dim(missingdat_Ammonia)
View(missingdat_Ammonia)
```

## tidy data format
```{r}
# check dataframe:
## check number of rows: 26 years x 12 months = 312 rows
## there are only 310 rows which means there are two missing rows of month x year that need NAs?
## add them back in

Date <- tibble(Date=seq(from=lubridate::as_date("1995-01-01"), to=lubridate::as_date("2020-12-01"), by="1 month")) # 312

# create a new table with all combos = 312
amm_table <- Date %>% 
  left_join(missingdat_Ammonia, by="Date")
```



# pilot model
Inspect a single station - see how the original time series is misleading,
needed the full combination of station-month-year with NAs

```{r}
# visualize missing data points - 7 missing amm data points
D28A_na <- amm_table %>% 
  select(Date, D28A) %>% # filter out station of interest
  filter(is.na(D28A)) %>% # find NAs
  mutate(D28A=0) # for visualization purposes set to zero

plot_D28A <- ggplot(amm_table, aes(Date, D28A))+
  geom_line()+
  geom_point(data=D28A_na, aes(Date, D28A), pch=4, col="red", size=3)+ # red x = NA
  theme_bw()
plot_D28A
```


## fit ARIMA model
```{r}
# time series object using ts - monthly resolution for each year
amm_D28A <- amm_table %>% 
  select(Date, D28A) %>% 
  arrange(Date) # single station still for now
amm_ts <- ts(amm_D28A$D28A, frequency = 12, start = c(1995,1), end=c(2020,12))
amm_ts


# fit arima model
amm_fit <- forecast::auto.arima(amm_ts, seasonal=TRUE, trace = TRUE, lambda = "auto", stationary=TRUE) #stationary=TRUE for forecasting
# get the same answer with lambda="auto" and unlog data
# if we let stationarity=FALSE, there's a different top model, but it doesn't allow forecasting?
summary(amm_fit)
```
Series: amm_ts 
ARIMA(2,0,0)(2,0,0)[12] with non-zero mean


## predict values using the calibration dataset
```{r}
amm_forecast <- forecast::forecast(amm_ts,model=amm_fit)
```

## compare predicted versus observed values
```{r}
#Plot the observed and predicted Ammonia
par(mar=c(2,4,1,1))
plot(amm_D28A$Date,amm_ts,xlab="Date",ylab="amm (C)",lwd=2,type="l")
lines(amm_D28A$Date,amm_forecast$fitted,col="red")

#Plot predicted versus observed values
plot(amm_ts,amm_forecast$fitted,xlab="Observed",ylab="Predicted",pch=".")
abline(0,1,lty=2)
R2 = round(cor.test(amm_ts,amm_forecast$fitted,na.rm=T)$estimate^2,2)
mtext(side=3,line=-2,adj=0.1,bquote(R^2 == .(R2)))


#Check the residuals
forecast::checkresiduals(amm_fit) 
#give also the results for the Ljung_Box test with H0 = randomly distributed errors (white noise)

#plot residuals versus fitted values (=check for heterosedasticity)
#if problems you might want to try to transform the data first
par(mar=c(4,4,4,4))
plot(amm_forecast$fitted,amm_forecast$residuals,ylab="Residuals",xlab="Fitted values")


#Check several metrics of performance
forecast::accuracy(object = amm_fit) # can also provide a test dataset for cross-validation using x = testUS 
#? ME: Mean Error
#? RMSE: Root Mean Squared Error
#? MAE: Mean Absolute Error
#? MPE: Mean Percentage Error
#? MAPE: Mean Absolute Percentage Error
#? MASE: Mean Absolute Scaled Error
#? ACF1: Autocorrelation of errors at lag 1.


#Missing data imputation
#Interpolate missing values using a Kalman filter (=smoother)
amm_inter <- na_kalman(amm_ts,model=amm_fit$model) #use the fitted model

#Plot the results - Doesn't do a good job with 1980 NAs
par(mar=c(2,4,1,1))
plot(amm_inter,xlab="",ylab="Ammonia (C)",col="red",main="Interpolation missing values")
lines(amm_ts,col="black")

#?auto.arima
```

# full model
```{r}
# run model and fit (takes forever)
df_ts <- create_ts_df(amm_table)
model_fits <- eval_fit(amm_table)
```

## diagnostic tests
```{r}
#Plot the observed and predicted Ammonia
ggplot(df_ts, aes(Date, Imputed_values, color=Imputed))+
  #geom_line(aes(Date, Imputed_values), col="gray60")+  
  geom_point(size=1)+
  facet_wrap(Station~., ncol=3, scales = "free_y")+
  scale_color_manual(values=c("gray60", "red", "black"))+
  labs(title="Replacing missing values with ARIMA and Kalman filter", subtitle="Dissolved ammonia")+
  theme_bw()
```

```{r}
# model summary
for (station in names(model_fits)){
  fit <- model_fits[station][[1]]
  # check summary
  print(summary(fit))  

  # check the residuals
  print(forecast::checkresiduals(fit))

  # check several metrics of performance
  print(forecast::accuracy(object = fit))

  # plot residuals versus fitted values (=check for heterosedasticity)
  # if problems you might want to try to transform the data first
  par(mar=c(4,4,4,4))
  plot(fit$fitted, fit$residuals, ylab = 'Residuals', xlab = 'Fitted values')
}
```

## export df
```{r}
df_ts %>% write_csv("data/missing_data/imputed_data/diss_ammonia_imputed_data.csv")
```



# DISSOLVED NITRATE/NITRITE

# data wrangling
## import data
This is data generated from the "nutrient_data_monthly.Rmd" script written by Sarah Perry (1-13-2022)
```{r}
missingdat_Nit <- read_csv("data/missing_data/missing_data/missingdat_DissNitrateNitrite.csv") %>%  
  mutate(Date=lubridate::as_date(MonthYear)) %>% 
  select(Date, Analyte:P8) %>%  # rearrange df with date, no time
  arrange(Date)
str(missingdat_Nit)
head(missingdat_Nit)
dim(missingdat_Nit)
View(missingdat_Nit)
```

## tidy data format
```{r}
# check dataframe:
## check number of rows: 26 years x 12 months = 312 rows
## there are only 310 rows which means there are two missing rows of month x year that need NAs?
## add them back in

Date <- tibble(Date=seq(from=lubridate::as_date("1995-01-01"), to=lubridate::as_date("2020-12-01"), by="1 month")) # 312

# create a new table with all combos = 312
nit_table <- Date %>% 
  left_join(missingdat_Nit, by="Date")
```



# pilot model
Inspect a single station - see how the original time series is misleading,
needed the full combination of station-month-year with NAs

```{r}
# visualize missing data points - 7 missing nit data points
D28A_na <- nit_table %>% 
  select(Date, D28A) %>% # filter out station of interest
  filter(is.na(D28A)) %>% # find NAs
  mutate(D28A=0) # for visualization purposes set to zero

plot_D28A <- ggplot(nit_table, aes(Date, D28A))+
  geom_line()+
  geom_point(data=D28A_na, aes(Date, D28A), pch=4, col="red", size=3)+ # red x = NA
  theme_bw()
plot_D28A
```


## fit ARIMA model
```{r}
# time series object using ts - monthly resolution for each year
nit_D28A <- nit_table %>% 
  select(Date, D28A) %>% 
  arrange(Date) # single station still for now
nit_ts <- ts(nit_D28A$D28A, frequency = 12, start = c(1995,1), end=c(2020,12))
nit_ts


# fit arima model
nit_fit <- forecast::auto.arima(nit_ts, seasonal=TRUE, trace = TRUE, lambda = "auto", stationary=TRUE) #stationary=TRUE for forecasting
# get the same answer with lambda="auto" and unlog data
# if we let stationarity=FALSE, there's a different top model, but it doesn't allow forecasting?
summary(nit_fit)
```
Series: nit_ts 
ARIMA(2,0,0)(2,0,0)[12] with non-zero mean


## predict values using the calibration dataset
```{r}
nit_forecast <- forecast::forecast(nit_ts,model=nit_fit)
```

## compare predicted versus observed values
```{r}
#Plot the observed and predicted Nit
par(mar=c(2,4,1,1))
plot(nit_D28A$Date,nit_ts,xlab="Date",ylab="nit (C)",lwd=2,type="l")
lines(nit_D28A$Date,nit_forecast$fitted,col="red")

#Plot predicted versus observed values
plot(nit_ts,nit_forecast$fitted,xlab="Observed",ylab="Predicted",pch=".")
abline(0,1,lty=2)
R2 = round(cor.test(nit_ts,nit_forecast$fitted,na.rm=T)$estimate^2,2)
mtext(side=3,line=-2,adj=0.1,bquote(R^2 == .(R2)))


#Check the residuals
forecast::checkresiduals(nit_fit) 
#give also the results for the Ljung_Box test with H0 = randomly distributed errors (white noise)

#plot residuals versus fitted values (=check for heterosedasticity)
#if problems you might want to try to transform the data first
par(mar=c(4,4,4,4))
plot(nit_forecast$fitted,nit_forecast$residuals,ylab="Residuals",xlab="Fitted values")


#Check several metrics of performance
forecast::accuracy(object = nit_fit) # can also provide a test dataset for cross-validation using x = testUS 
#? ME: Mean Error
#? RMSE: Root Mean Squared Error
#? MAE: Mean Absolute Error
#? MPE: Mean Percentage Error
#? MAPE: Mean Absolute Percentage Error
#? MASE: Mean Absolute Scaled Error
#? ACF1: Autocorrelation of errors at lag 1.


#Missing data imputation
#Interpolate missing values using a Kalman filter (=smoother)
nit_inter <- na_kalman(nit_ts,model=nit_fit$model) #use the fitted model

#Plot the results - Doesn't do a good job with 1980 NAs
par(mar=c(2,4,1,1))
plot(nit_inter,xlab="",ylab="Nit (C)",col="red",main="Interpolation missing values")
lines(nit_ts,col="black")

#?auto.arima
```

# full model
```{r}
# run model and fit (takes forever)
df_ts <- create_ts_df(nit_table)
model_fits <- eval_fit(nit_table)
```

## diagnostic tests
```{r}
#Plot the observed and predicted Nit
ggplot(df_ts, aes(Date, Imputed_values, color=Imputed))+
  #geom_line(aes(Date, Imputed_values), col="gray60")+  
  geom_point(size=1)+
  facet_wrap(Station~., ncol=3, scales = "free_y")+
  scale_color_manual(values=c("gray60", "red", "black"))+
  labs(title="Replacing missing values with ARIMA and Kalman filter", subtitle="Dissolved Nitrate/Nitrite")+
  theme_bw()
```

```{r}
# model summary
for (station in names(model_fits)){
  fit <- model_fits[station][[1]]
  # check summary
  print(summary(fit))  

  # check the residuals
  print(forecast::checkresiduals(fit))

  # check several metrics of performance
  print(forecast::accuracy(object = fit))

  # plot residuals versus fitted values (=check for heterosedasticity)
  # if problems you might want to try to transform the data first
  par(mar=c(4,4,4,4))
  plot(fit$fitted, fit$residuals, ylab = 'Residuals', xlab = 'Fitted values')
}
```

## export df
```{r}
df_ts %>% write_csv("data/missing_data/imputed_data/diss_nitrate_nitrite_imputed_data.csv")
```

